# @package _global_

defaults:
  - planner_learn_kinematic_oracle_humanoid_spot_fp # pop_play_kinematic_oracle_humanoid_spot_fp
  - /habitat/task/lab_sensors:
    # For the oracle navigation
    - has_finished_oracle_nav
  - /habitat/task/actions@habitat.task.actions.agent_0_pick_base_velocity: base_velocity
  - /habitat/task/actions@habitat.task.actions.agent_0_place_base_velocity: base_velocity
  - /habitat/task/actions@habitat.task.actions.agent_0_reset_arm_action: arm_action
  - override /habitat/task/actions@habitat.task.actions.agent_0_base_velocity: base_velocity_non_cylinder
  - override /habitat_baselines/rl/policy@habitat_baselines.rl.policy.agent_0: hab3_hl_neural_ma
  # - override /habitat_baselines/rl/policy@habitat_baselines.rl.policy.agent_1: hab3_hl_neural_ma
  - _self_

hydra:
  job:
    name: 'pop_play_humanoid_spot_fp'

habitat:
  gym:
    obs_keys:
      - agent_0_articulated_agent_arm_depth
      - agent_0_relative_resting_position
      - agent_0_obj_start_sensor
      - agent_0_obj_goal_sensor
      - agent_0_obj_start_gps_compass
      - agent_0_obj_goal_gps_compass
      - agent_0_is_holding
      - agent_0_ee_pos
      - agent_0_joint
      - agent_0_localization_sensor
      - agent_0_has_finished_oracle_nav
      - agent_0_other_agent_gps
      - agent_0_should_replan
      - agent_1_head_depth
      - agent_1_relative_resting_position
      - agent_1_obj_start_sensor
      - agent_1_obj_goal_sensor
      - agent_1_obj_start_gps_compass
      - agent_1_obj_goal_gps_compass
      - agent_1_is_holding
      - agent_1_ee_pos
      - agent_1_localization_sensor
      - agent_1_has_finished_oracle_nav
      - agent_1_other_agent_gps
      - agent_1_should_replan
      - all_predicates
  simulator:
    agents:
      agent_1:
        radius: 0.3
  task:
    desired_resting_position: [0.45, 0.0, 0.43]
    actions:
      agent_0_arm_action:
        type: "ArmAction"
        arm_controller: "ArmRelPosMaskKinematicAction"
        arm_joint_mask: [1,1,0,1,1,1,1]
        arm_joint_dimensionality: 7
        grasp_thresh_dist: 0.2
        disable_grip: False
        should_clip: True
        delta_pos_limit: 0.25
        ee_ctrl_lim: 0.015

      agent_0_reset_arm_action:
        type: "ArmAction"
        arm_controller: "ArmRelPosMaskKinematicAction"
        arm_joint_mask: [1,1,0,1,1,1,1]
        arm_joint_dimensionality: 7
        disable_grip: True
        should_clip: False
        gym_action_prefix: "immediate_reset_arm"
        delta_pos_limit: 1.0

      agent_0_base_velocity:
        allow_dyn_slide: True
        # There is a collision if the difference between the clamped NavMesh position and target position
        # is more than than collision_threshold for any point
        collision_threshold: 1e-5
        # The x and y locations of the clamped NavMesh position
        navmesh_offset: [[0.0, 0.0], [0.275, 0.0]]
        # If we allow the robot to move laterally
        enable_lateral_move: False
        # speed parameters
        longitudinal_lin_speed: 10.0
        lateral_lin_speed: 10.0
        ang_speed: 10.0
        enable_rotation_check_for_dyn_slide: False

      # agent_0_base_velocity:
      #   lin_speed: 5.0
      #   ang_speed: 5.0

      agent_0_pick_base_velocity:
        lin_speed: 5.0
        ang_speed: 5.0
        gym_action_prefix: pick_base_vel
      agent_0_place_base_velocity:
        lin_speed: 5.0
        ang_speed: 5.0
        gym_action_prefix: place_base_vel

habitat_baselines:
  rl:
    policy:
      agent_0:
        hierarchical_policy:
          defined_skills:
            pick:
              skill_name: "PickSkillPolicy"
              obs_skill_inputs: ["obj_start_sensor"]
              load_ckpt_file: "/fsx-siro/jimmytyyang/rl_log/checkpoints_pick/pick_latest.pth"
              max_skill_steps: 100 # We reduce the max skill steps so that the high-level policy can replan as soon as possible when the grasping fails
              reset_joint_state: [0.0, -3.14, 0.0, 3.0, 0.0, 0.0, 0.0]
              apply_postconds: False
            place:
              skill_name: "PlaceSkillPolicy"
              obs_skill_inputs: ["obj_goal_sensor"]
              max_skill_steps: 100 # We reduce the max skill steps so that the high-level policy can replan as soon as possible when the grasping fails
              apply_postconds: False
              reset_joint_state: [0.0, -3.14, 0.0, 3.0, 0.0, 0.0, 0.0]
              load_ckpt_file: "/fsx-siro/jimmytyyang/rl_log/checkpoints_place/place_ckpt.343.pth"
            nav_to_obj:
              skill_name: "NavSkillPolicy"
              obs_skill_inputs: ["goal_to_agent_gps_compass"]
              load_ckpt_file: "/fsx-siro/jimmytyyang/rl_log/checkpoints_as21NCAR_2/latest.pth"
              # load_ckpt_file: "multirun/checkpoints_jimmy/jimmy_nav.pth"
              max_skill_steps: 2000
              obs_skill_input_dim: 2
              pddl_action_names: ["nav_to_obj", "nav_to_goal", "nav_to_robot", "nav_to_receptacle_by_name"]

      agent_1:
        hierarchical_policy:
          defined_skills:
            pick:
              max_skill_steps: 15


            place:
              max_skill_steps: 15
