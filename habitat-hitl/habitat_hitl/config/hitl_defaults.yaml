habitat_baselines:
  # some defaults for interactive HITL applications
  evaluate: True
  num_environments: 1

habitat_hitl:
  # HitlDriver or HitlBareSimDriver. HitlDriver creates a Habitat-lab env. HitlBareSimDriver only creates a Habitat-sim simulator.
  driver: "HitlDriver"
  window:
    # title displayed in application title bar GUI
    title: "Habitat HITL Application"
    # Horizontal resolution of the window.
    width: 1280
    # Vertical resolution of the window.
    height: 720
    # Font to display in the GUI app. To add a new font, include it to "../core/fonts" and adjust "display_font_size" accordingly.
    display_font_path: "../core/fonts/IBMPlexSans-Regular.ttf"
    # Font size for text displayed in the GUI app.
    display_font_size: 16

  networking:
    # When enabled, we run a websocket server that connects to remote clients. A HITL app with networking enabled is an "HITL server". See pick_throw_vr example app.
    enable: False

    # Number of accepted concurrent clients (multiplayer if higher than one). All connections beyond this count will be rejected. Beware that this can be different from the agent count.
    max_client_count: 1

    # Accept incoming connections by default. If disabled, connections must be activated using InterprocessRecord.enable_new_connections().
    enable_connections_by_default: True

    # We'll listen for incoming client connections at this port.
    port: 8888

    # If True, NetworkManager will wait until the application issues ClientMessageManager.signal_app_ready before sending the first gfx-replay keyframe to the client. This gives the application an opportunity to e.g. change scenes when a client connects. If False, NetworkManager will start sending keyframes immediately upon connect.
    wait_for_app_ready_signal: False

    # Used with AWS elastic load balancer (ELB) health checks. If enabled, we run a separate HTTP server that returns a code based on whether the HITL server is available to accept new client connections. Note this HTTP server doesn't serve any files or other content. Note the current HITL server implementation only handles one client at a time, so the expected behavior is that it becomes "unavailable" once it has a connected client. The HTTP server can be tested locally with e.g. curl -i 0.0.0.0:8889.
    http_availability_server:
      enable: False
      port: 8889
      # HTTP codes
      code_available: 200  # "Ok"
      code_unavailable: 503  # "Service Unavailable"

    # Optionally kick an idle client after n seconds.
    client_max_idle_duration: ~

    # Override incoming client connection parameters for testing purposes.
    mock_connection_params_dict: None

    client_sync:
      # If enabled, the server main camera transform will be sent to the client. Disable if the client should control its own camera (e.g. VR), or if clients must use different camera transforms (e.g. multiplayer).
      server_camera: True
      # If enabled, the first client input is relayed to the server's GuiInput. Disable if clients have independent controls from the server.
      server_input: True
      # Enable transmission of skinned mesh poses. If 'camera.first_person_mode' is enabled, you should generally disable this as well as enable `hide_humanoid_in_gui` because the humanoid will occlude the camera.
      skinning: True

  # Target rate to step the environment (steps per second); actual SPS may be lower depending on your hardware
  target_sps: 30

  # Width in pixels. Note that actual width depends on device/OpenGL, and large widths (10+) aren't usually supported.
  debug_line_width: 3

  # Episodes filter in the form '0:10 12 14:20:2', where single integer number (`12` in this case) represents an episode id, colon separated integers (`0:10' and `14:20:2`) represent start:stop:step ids range.
  episodes_filter: ~

  experimental:
    # Choose between classic and batch renderer. This is an experimental feature aimed at those of us building the batch renderer.
    use_batch_renderer: False
    headless:
      # Run without a GUI window. For unit-testing or use with networking.enable as a headless server.
      do_headless: False
      # Shortly after app startup, write debug images from the first K steps to video files. See debug_third_person_viewport and debug_images.
      debug_video_writer:
        num_frames_to_save: 0
        filepath_base: "./debug_video"
      # force app exit after K steps
      exit_after: ~

  # Disable policy-initialization and environment-stepping. Useful for testing on lower-power machines.
  disable_policies_and_stepping: False

  debug_third_person_viewport:
    # If specified, enable the debug third-person camera (habitat.simulator.debug_render) with specified viewport width. If height (below) is not specified, assume square aspect ratio (height==width). This is considered an additional debug image (see also debug_images below).
    width: ~
    # If specified, use the specified viewport height for the debug third-person camera.
    height: ~

  # Visualize camera sensors in the app GUI. For example, to visualize agent1's head depth sensor, include "agent_1_head_depth" in this list.
  debug_images: []

  # The speed of the default animation timer. See app_service.get_anim_fraction. Currently used to animate some debug lines.
  viz_animation_speed: 2.0

  # Hide the humanoid in the GUI viewport. Note it will still be rendered into observations fed to policies. Mainly used for camera first-person mode (below).
  hide_humanoid_in_gui: False

  # Object grasp/place proximity threshold. See GuiPickHelper.
  can_grasp_place_threshold: 1.2

  # See GuiHumanoidController.
  walk_pose_path: "data/humanoids/humanoid_data/walking_motion_processed_smplx.pkl"

  camera:
    # See CameraHelper. Set first_person_mode=True, or False to use third-person mode. With first-person mode, use  `max_look_up_angle` and `min_look_down_angle` arguments to limit humanoid's look up/down angle. For example, `--max-look-up-angle 0 --min-look-down-angle -45` to let the humanoid look down -45 degrees. You should also generally use `hide_humanoid_in_gui=True` with `first_person_mode`, because it doesn't make sense to visualize the humanoid with this camera. For first-person mode, you should also set gui_controlled_agent.ang_speed=300 to avoid delayed movement after turning.
    first_person_mode: False
    max_look_up_angle: 15.0
    min_look_down_angle: -60.0

  # list of gui-controlled agents. Each list item should be a dict following the commented-out reference format below. Beware some apps only support one (or zero!) gui-controlled agent. For each Habitat env agent *without* a corresponding entry here, it will be policy-controlled.
  gui_controlled_agents: []
    # agent index corresponding to a Habitat env agent
    # - agent_index: 0
    # linear speed. Applies only to KinematicHumanoid. For SpotRobot, see habitat.task.actions.agent_0_base_velocity.ang_speed.
    #   lin_speed: 10.0
    # angular speed. Applies only to KinematicHumanoid. For SpotRobot, see habitat.task.actions.agent_0_base_velocity.lin_speed.
    #   ang_speed: 10.0

  data_collection:
    # Filepath base used for saving various session data files, e.g. `my_output/my_session`. Specify a full path including basename, but not an extension.
    save_filepath_base: null

    # Save recorded episode data to file. Use save_filepath_base (above) to specify the filepath base. The first episode will be saved as `my_output/my_session.0.json.gz` and `my_output/my_session.0.pkl.gz`. These files contain mostly-identical data; we save both so that developers have two choices for how to consume the data later. The second episode will be saved as `my_session.1.json.gz`, etc. For an example of consuming this data, see `test_episode_save_files.py` .
    save_episode_record: False

    # Save the gfx-replay keyframes to file. Use save_filepath_base to specify the filepath base. Gfx-replay files can be used elsewhere in Habitat, e.g. https://github.com/facebookresearch/habitat-lab/pull/1041. Capturing ends (is saved) when the session is over (pressed ESC). The file will be saved as `my_output/my_session.gfx_replay.json.gz`.
    save_gfx_replay_keyframes: False

  # todo: document
  video_recorder:
    output_file_path_prefix: "video"